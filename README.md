ðŸ”¬ Explainable AI for Clinical Decision Support: Enhancing Medical Transparency
Modern healthcare relies heavily on AI-powered systems for decision-making, yet trust and transparency remain critical challenges. To address this, I led a research project focused on integrating Explainable AI (XAI) methods into clinical decision support systems (CDSS). This initiative aims to provide interpretable medical recommendations, fostering clinician trust and enhancing adoption.

ðŸŒŸ Key Highlights:
Research Objectives:
Develop a system to recommend medicines with detailed explanations.
Enhance decision-making by providing transparent insights into AI-driven recommendations.

Innovative Approach:
Expanded a recommendation system to output:
Similar medicines with detailed information on side effects.
Suitability for specific conditions such as alcoholism, pregnancy, and liver damage and etc.
Leveraged state-of-the-art XAI techniques to provide clinicians with interpretable justifications for recommendations.

Dataset and Techniques:
Utilized a curated medicine dataset containing diverse medical properties.
Applied cosine similarity to enhance the accuracy of recommendations.
Incorporated XAI methodologies for visual and textual explanations.

Impact:
Empowers healthcare professionals to make informed, evidence-based decisions.
Increases trust in AI by demystifying its decision-making processes.
